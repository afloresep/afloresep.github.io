---
layout: archive  
permalink: /coursework/  
author_profile: true  
---

Welcome to the coursework section! Here, you'll find my collection of notes, articles, and reflections on various topics related to **Machine Learning (ML)**, **Artificial Intelligence (AI)**, and **Computer Vision (CV)**. These resources are aimed at documenting my learning journey, especially during my PhD, and are meant to serve as a study guide for anyone delving into these exciting fields. 

## TMAP
A significant portion of my PhD work revolves around **TMAP**, a versatile tool in my research. To deepen my understanding of this tool, I’ve dedicated some time to exploring its concepts and implementation. The key topics involved, such as **Locality-Sensitive Hashing (LSH)** and **Min-Hashing**, are critical components of the larger framework.

I've written a detailed blog post that offers a foundational introduction to **TMAP** and breaks down its core mechanisms. Below are links to some of the key concepts discussed within the post:

1. **[TMAP Overview](https://afloresep.github.io/TMAP/):**  
   This post provides a comprehensive introduction to TMAP, explaining its role, functionality, and how it fits into the broader landscape of data mapping and visualization.

   - **[Min-Hashing](https://afloresep.github.io/posts/2024/09/MinHashing/):**  
     A dive into Min-Hashing, explaining how it efficiently estimates the similarity between datasets using hashed subsets of the data.
     
   - **[LSH Forest](https://afloresep.github.io/posts/2024/09/LSH-Forest/):**  
     An overview of Locality-Sensitive Hashing (LSH) and how the LSH Forest algorithm is used to approximate nearest neighbors in high-dimensional spaces.
     
   - **[K-NN Graph](https://afloresep.github.io/posts/2024/09/knn-graph/):**  
     A breakdown of K-Nearest Neighbor (K-NN) graphs and how they are applied in data clustering and classification.

More posts on related concepts and applications will be added soon as I continue to expand my research.

## Computer Vision
I will be documenting my progress in **HS2024 - Computer Vision**, a course offered by Universität Bern, which covers key concepts in CV. My notes dive into various topics that form the backbone of the field:

1. **[Projection Models](https://afloresep.github.io/computer-vision/Projection-Models/):**  
   This post provides a detailed explanation of camera models and the mathematics behind projecting 3D objects onto 2D images. It covers the essentials of camera calibration, perspective projection, and the pinhole camera model.

Future posts will cover other critical aspects of the course, including:
- Algorithms for image processing such as image filtering and image segmentation
- Algorithms for object detection (such as faces) and recognition
- Algorithms for 3D reconstruction (e.g., from stereo systems) Describe the mathematics underpinning each method and know how to adapt it to new scenarios.
  
These notes will form a comprehensive resource for anyone interested in the technical foundations and applications of computer vision.

## Machine Learning
Machine learning is the driving force behind much of modern AI, powering systems that can learn from data, recognize patterns, and make informed decisions. I will soon be adding a section dedicated to my work in machine learning, including:
- Supervised learning
- Unsupervised learning
- Reinforcement learning
These topics are explored through a probabilistic framework, with a strong emphasis on optimization techniques throughout the course.
  
Also expect detailed posts covering essential algorithms such as **Support Vector Machines**, **Decision Trees**, and **Convolutional Neural Networks (CNNs)**.

## Applied Optimization
An applied introduction, covering a broad range of practically important topics, as for instance: Mathematical modeling of real-world problems, theory of convexity, Lagrange dualism, algorithms for unconstrained and constrained optimization with inequalities (e.g. gradient descent, Newton’s method, trust-region methods, active set approaches, interior point methods, …).
Hopefully by the end of the course I will be able to: 
- Understand which classes of optimization problems are easy/hard to solve.
- Model or re-formulate problems in a way that they become easier (e.g. convex).
- Understand the fundamental ideas behind unconstrained, constrained and mixed-integer optimization.
- Implement and use various optimization algorithms (programming exercises are in C++).
- Understand and tune the parameters and output statistics that are exposed by optimization packages.

---

As I progress through my PhD and research projects, I will continue to update this space with more notes, tutorials, and insights. Keep an eye out for new additions, and feel free to reach out if you'd like to discuss any of these topics in more detail!

